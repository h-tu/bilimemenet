# Prompt Tuning
## Set up for Juypter Notebook
We first mount google drive, then clone the Pangu code repo.
```python
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

%cd /content/drive/MyDrive/nlp/bilimemenet
!git clone https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-Applications.git
```

Install required packages `sentencepiece` and `apex` on Google Drive, so that we do not need to install them every time we open a new session.
```python
nb_path = '/content/drive/MyDrive/nlp/Pangu/data/dependency/lib'
sys.path.insert(0, nb_path)

!pip install --target=$nb_path sentencepiece

!git clone https://github.com/NVIDIA/apex
%cd apex
!pip install -v --target=$nb_path --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
```


Upload our bilibili dataset and Pangu pretrained 2.6B model to Google Drive, and save their absolute paths for later use.

## Data preprocessing
For our code for data preprocessing, please see `Pangu/peek_data.ipynb`.

This part relies on the pickle files generated by `Chinese-Bert/pre_process.ipynb`.

## Prompt tuning
For our code for prompt tuning, please see `Pangu/app/`.

Our implementation relies on code of building model and processing global arguments from Pangu [repo](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-Applications.git).

We implemented reading bili data, inference and prompt tune. We also included the scripts for starting two process.