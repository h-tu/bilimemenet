{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f22941f",
   "metadata": {},
   "source": [
    "# Get Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e575c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1hTp8qDF4r2tTk7W6SBnfYyRoNwwSdkap/view?usp=sharing\n",
    "!gdown --id 1hTp8qDF4r2tTk7W6SBnfYyRoNwwSdkap\n",
    "#https://drive.google.com/file/d/1T-yZGWyPC89SCCbm1m0DrRMGyDlUaonl/view?usp=sharing\n",
    "!gdown --id 1T-yZGWyPC89SCCbm1m0DrRMGyDlUaonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0f77c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337392\n",
      "337392\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "token_file = open(\"danmu_token_main.pkl\", \"rb\")\n",
    "dist_file = open(\"danmu_dist_main.pkl\", \"rb\")\n",
    "\n",
    "tokens = pickle.load(token_file)\n",
    "dists = pickle.load(dist_file)\n",
    "\n",
    "print(len(tokens))\n",
    "print(len(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6083cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = [np.argmax(i) for i in dists]\n",
    "\n",
    "label_distribution = {}\n",
    "for i in labels:\n",
    "    if i in label_distribution:\n",
    "        label_distribution[i] += 1\n",
    "    else:\n",
    "        label_distribution[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a37194d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e10f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label with no data\n",
    "label_list = list(label_distribution.keys())\n",
    "labels = [label_list.index(i) for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66903730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.DataFrame({\n",
    "    'text': tokens,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4500362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging\n",
    "train_df = train_df[train_df['text'] != 'nan']\n",
    "test_df = test_df[test_df['text'] != 'nan']\n",
    "val_df = val_df[val_df['text'] != 'nan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "384befc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>那是脐带哥哥</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>原来有人脉</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>想去了</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>百香果射手</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>中国政法大学</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26987</th>\n",
       "      <td>匹克嗯</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26988</th>\n",
       "      <td>321看钉宫</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26989</th>\n",
       "      <td>露露哇露露打</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26990</th>\n",
       "      <td>这是臭虫吧</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26991</th>\n",
       "      <td>不吃牛肉</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  label\n",
       "0      那是脐带哥哥     10\n",
       "1       原来有人脉      8\n",
       "2         想去了      1\n",
       "3       百香果射手      1\n",
       "4      中国政法大学      6\n",
       "...       ...    ...\n",
       "26987     匹克嗯     12\n",
       "26988  321看钉宫      8\n",
       "26989  露露哇露露打      4\n",
       "26990   这是臭虫吧      0\n",
       "26991    不吃牛肉      1\n",
       "\n",
       "[26992 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.reset_index(drop=True)\n",
    "test_df.reset_index(drop=True)\n",
    "val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27447e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d612ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "\n",
    "train_df.to_csv('data_csv/train.csv', index = False)\n",
    "test_df.to_csv('data_csv/test.csv', index = False)\n",
    "val_df.to_csv('data_csv/val.csv', index = False)\n",
    "\n",
    "# train_dict = train_df.to_dict()\n",
    "# test_dict = test_df.to_dict()\n",
    "# val_dict = val_df.to_dict()\n",
    "# train_data_json = {\n",
    "#     'train' : train_dict,\n",
    "#     'test' : test_dict,\n",
    "#     'validation': val_dict\n",
    "# }\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open('data_csv/data.json', 'w') as f:\n",
    "#     json.dump(train_data_json, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04e8cd",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f6a0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "train = datasets.Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val = datasets.Dataset.from_pandas(val_df, preserve_index=False)\n",
    "test = datasets.Dataset.from_pandas(test_df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a915b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7e82a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb6aff0bf546f9a91b2e1cedb68087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c3fe032d8049e5972f3e098fca8440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47c9bce1a774028b82c6905255e85e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "tokenized_train =  train.map(preprocess_function, batched=True)\n",
    "tokenized_val =  val.map(preprocess_function, batched=True)\n",
    "tokenized_test = test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f381a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For batching and padding\n",
    "import transformers \n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76d4b1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b91b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/uer/chinese_roberta_L-12_H-768/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/0581d850743cad42501488567cceb8dc9ce50d9f05ad632d273b4389b2f52f68.042085124aedc502028136283b7bf9a169a238009bd6c309f049b249216061a2\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/chinese_roberta_L-12_H-768\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "https://huggingface.co/uer/chinese_roberta_L-12_H-768/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/ec2-user/.cache/huggingface/transformers/tmp3b7kkq53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602a4bb9fe34f5bade5f6db539685f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/390M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/uer/chinese_roberta_L-12_H-768/resolve/main/pytorch_model.bin in cache at /home/ec2-user/.cache/huggingface/transformers/8150d6a23b0f518134caba5b6141414848a8adbe069f59c18ddbdd9b7498045c.a61653c00cec4d0c4b7281005a15c05b7277d845fb82d1967138f8296cc7622b\n",
      "creating metadata file for /home/ec2-user/.cache/huggingface/transformers/8150d6a23b0f518134caba5b6141414848a8adbe069f59c18ddbdd9b7498045c.a61653c00cec4d0c4b7281005a15c05b7277d845fb82d1967138f8296cc7622b\n",
      "loading weights file https://huggingface.co/uer/chinese_roberta_L-12_H-768/resolve/main/pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/transformers/8150d6a23b0f518134caba5b6141414848a8adbe069f59c18ddbdd9b7498045c.a61653c00cec4d0c4b7281005a15c05b7277d845fb82d1967138f8296cc7622b\n"
     ]
    }
   ],
   "source": [
    "# model = transformers.AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-jd-full-chinese\",\\\n",
    "#                                                                         num_labels = len(label_distribution), \\\n",
    "#                                                                        ignore_mismatched_sizes=True)\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained(\"t5-small\")\n",
    "                                                                        #num_labels = len(label_distribution))\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"t5_small\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b161d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19202124",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_train,\n",
    "    eval_dataset = tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451394ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23cb1cf",
   "metadata": {},
   "source": [
    "# SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24cd7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: arn:aws:iam::635837196364:role/service-role/AmazonSageMaker-ExecutionRole-20220427T210117\n",
      "bucket: sagemaker-us-east-1-635837196364\n",
      "session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "session_bucket = None\n",
    "if session_bucket == None and session is not None:\n",
    "    session_bucket = session.default_bucket()\n",
    "    \n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session(default_bucket = session_bucket)\n",
    "\n",
    "print(f'role: {role}')\n",
    "print(f'bucket: {session_bucket}')\n",
    "print(f'session region: {session.boto_region_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d80167e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_train\n",
    "test_dataset = datasets.concatenate_datasets([tokenized_val, tokenized_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107ea3d",
   "metadata": {},
   "source": [
    "Upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001dab77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-635837196364/dataset/danmu_main/val/val.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = 'dataset/danmu_main'\n",
    "\n",
    "#save data to S3\n",
    "train_input_path = f's3://{session.default_bucket()}/{s3_prefix}/train'\n",
    "#train_dataset.save_to_disk(train_input_path, fs = s3)\n",
    "session.upload_data(path='data_csv/train.csv', bucket=session_bucket, key_prefix=s3_prefix+'/train')\n",
    "\n",
    "test_input_path = f's3://{session.default_bucket()}/{s3_prefix}/test'\n",
    "#test_dataset.save_to_disk(test_input_path, fs = s3)\n",
    "session.upload_data(path='data_csv/test.csv', bucket=session_bucket, key_prefix=s3_prefix+'/test')\n",
    "\n",
    "val_input_path = f's3://{session.default_bucket()}/{s3_prefix}/val'\n",
    "session.upload_data(path='data_csv/val.csv', bucket=session_bucket, key_prefix=s3_prefix+'/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb770f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# gets role for executing training job\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_name_or_path':'t5-small',\n",
    "    'output_dir':'/opt/ml/model/t5_small',\n",
    "    # add your remaining hyperparameters \n",
    "    # more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/text-classification\n",
    "    'max_seq_length':128,\n",
    "    'per_device_train_batch_size' : 64,\n",
    "    'learning_rate' : 2e-5,\n",
    "    'num_train_epochs': 1,\n",
    "    #train\n",
    "    'do_train': True,\n",
    "    #data\n",
    "    'train_file': '/opt/ml/input/data/train/train.csv',\n",
    "    #'test_file': '/opt/ml/input/data/train/test.csv',\n",
    "    'validation_file': '/opt/ml/input/data/val/val.csv',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb7e65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_glue_t5.py',\n",
    "    #entry_point='run_glue.py',\n",
    "    #source_dir='./examples/pytorch/text-classification',\n",
    "    source_dir = './scripts',\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    #it_config=git_config,\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    hyperparameters = hyperparameters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd63f2dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 19:14:05 Starting - Starting the training job...\n",
      "2022-05-11 19:14:32 Starting - Preparing the instances for trainingProfilerReport-1652296445: InProgress\n",
      ".........\n",
      "2022-05-11 19:15:52 Downloading - Downloading input data\n",
      "2022-05-11 19:15:52 Training - Downloading the training image...........................\n",
      "2022-05-11 19:20:32 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-11 19:20:31,297 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-11 19:20:31,319 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-11 19:20:31,326 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-11 19:20:31,938 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"do_train\": true,\n",
      "        \"learning_rate\": 2e-05,\n",
      "        \"max_seq_length\": 128,\n",
      "        \"model_name_or_path\": \"t5-small\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/opt/ml/model/t5_small\",\n",
      "        \"per_device_train_batch_size\": 64,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/train.csv\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/val/val.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-05-11-19-14-04-508\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-19-14-04-508/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_glue_t5\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_glue_t5.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"do_train\":true,\"learning_rate\":2e-05,\"max_seq_length\":128,\"model_name_or_path\":\"t5-small\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model/t5_small\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"validation_file\":\"/opt/ml/input/data/val/val.csv\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_glue_t5.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_glue_t5\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-19-14-04-508/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"do_train\":true,\"learning_rate\":2e-05,\"max_seq_length\":128,\"model_name_or_path\":\"t5-small\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model/t5_small\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"validation_file\":\"/opt/ml/input/data/val/val.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2022-05-11-19-14-04-508\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-19-14-04-508/source/sourcedir.tar.gz\",\"module_name\":\"run_glue_t5\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_glue_t5.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--do_train\",\"True\",\"--learning_rate\",\"2e-05\",\"--max_seq_length\",\"128\",\"--model_name_or_path\",\"t5-small\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/opt/ml/model/t5_small\",\"--per_device_train_batch_size\",\"64\",\"--train_file\",\"/opt/ml/input/data/train/train.csv\",\"--validation_file\",\"/opt/ml/input/data/val/val.csv\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=t5-small\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model/t5_small\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=/opt/ml/input/data/train/train.csv\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FILE=/opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/urllib3-1.26.8-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdo_eval=False,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=IntervalStrategy.NO,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_strategy=HubStrategy.EVERY_SAVE,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=2e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=-1,\u001b[0m\n",
      "\u001b[34mlog_level_replica=-1,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/t5_small/runs/May11_19-20-37_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=SchedulerType.LINEAR,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=1.0,\u001b[0m\n",
      "\u001b[34moptim=OptimizerNames.ADAMW_HF,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model/t5_small,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=64,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model/t5_small,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - __main__ - load a local file for train: /opt/ml/input/data/train/train.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - __main__ - load a local file for validation: /opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - WARNING - datasets.builder - Using custom data configuration default-fb90e08dd36f9e4a\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.builder - Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-fb90e08dd36f9e4a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-fb90e08dd36f9e4a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 9248.74it/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 2098.20it/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.utils.info_utils - Unable to verify checksums.\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.builder - Generating split train\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.builder - Generating split validation\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:37 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-fb90e08dd36f9e4a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 431.67it/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:37,866 >> https://huggingface.co/t5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwg7r8ff7\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:37,866 >> https://huggingface.co/t5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwg7r8ff7\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 1.17k/1.17k [00:00<00:00, 1.34MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:37,895 >> storing https://huggingface.co/t5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:37,895 >> storing https://huggingface.co/t5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:37,896 >> creating metadata file for /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:37,896 >> creating metadata file for /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:37,896 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:37,896 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:37,897 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:37,897 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:344] 2022-05-11 19:20:37,928 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:344] 2022-05-11 19:20:37,928 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:37,955 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:37,955 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:37,956 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:37,956 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,026 >> https://huggingface.co/t5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2r_xtjh6\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,026 >> https://huggingface.co/t5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2r_xtjh6\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/773k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 773k/773k [00:00<00:00, 48.8MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:38,095 >> storing https://huggingface.co/t5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:38,095 >> storing https://huggingface.co/t5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:38,095 >> creating metadata file for /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:38,095 >> creating metadata file for /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,123 >> https://huggingface.co/t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcei571ra\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,123 >> https://huggingface.co/t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcei571ra\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 1.32M/1.32M [00:00<00:00, 80.0MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:38,198 >> storing https://huggingface.co/t5-small/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:38,198 >> storing https://huggingface.co/t5-small/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:38,198 >> creating metadata file for /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:38,198 >> creating metadata file for /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 19:20:38,291 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:38,317 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 19:20:38,317 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:38,318 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 19:20:38,318 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,409 >> https://huggingface.co/t5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp679zf08h\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 19:20:38,409 >> https://huggingface.co/t5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp679zf08h\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/231M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   4%|▎         | 8.38M/231M [00:00<00:02, 87.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 16.8M/231M [00:00<00:02, 87.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█         | 25.4M/231M [00:00<00:02, 88.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  15%|█▍        | 34.2M/231M [00:00<00:02, 90.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  19%|█▊        | 42.9M/231M [00:00<00:02, 89.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  22%|██▏       | 51.9M/231M [00:00<00:02, 91.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▋       | 60.6M/231M [00:00<00:01, 90.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  30%|███       | 69.4M/231M [00:00<00:01, 90.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  34%|███▍      | 78.1M/231M [00:00<00:01, 88.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 86.7M/231M [00:01<00:01, 89.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  41%|████      | 95.2M/231M [00:01<00:01, 86.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▍     | 103M/231M [00:01<00:01, 86.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  49%|████▉     | 113M/231M [00:01<00:01, 89.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 121M/231M [00:01<00:01, 88.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  56%|█████▌    | 130M/231M [00:01<00:01, 87.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  60%|█████▉    | 138M/231M [00:01<00:01, 86.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  63%|██████▎   | 146M/231M [00:01<00:01, 86.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  67%|██████▋   | 154M/231M [00:01<00:00, 85.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  70%|███████   | 163M/231M [00:01<00:00, 85.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  74%|███████▍  | 171M/231M [00:02<00:00, 86.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  78%|███████▊  | 180M/231M [00:02<00:00, 87.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████▏ | 188M/231M [00:02<00:00, 86.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  85%|████████▌ | 197M/231M [00:02<00:00, 87.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  89%|████████▉ | 206M/231M [00:02<00:00, 89.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 214M/231M [00:02<00:00, 89.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  97%|█████████▋| 223M/231M [00:02<00:00, 88.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 231M/231M [00:02<00:00, 87.8MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:41,189 >> storing https://huggingface.co/t5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 19:20:41,189 >> storing https://huggingface.co/t5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:41,189 >> creating metadata file for /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 19:20:41,189 >> creating metadata file for /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1431] 2022-05-11 19:20:41,190 >> loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1431] 2022-05-11 19:20:41,190 >> loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1702] 2022-05-11 19:20:41,966 >> All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1704] 2022-05-11 19:20:41,966 >> Some weights of MT5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['lm_head.weight', 'decoder.embed_tokens.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1702] 2022-05-11 19:20:41,966 >> All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1704] 2022-05-11 19:20:41,966 >> Some weights of MT5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['lm_head.weight', 'decoder.embed_tokens.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/243 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-fb90e08dd36f9e4a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ae2d9d218c49982d.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1/243 [00:00<00:27,  8.93ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 4/243 [00:00<00:16, 14.19ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 7/243 [00:00<00:13, 17.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 10/243 [00:00<00:11, 20.38ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 13/243 [00:00<00:10, 21.42ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 16/243 [00:00<00:10, 21.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 19/243 [00:00<00:09, 22.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 22/243 [00:01<00:09, 22.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 25/243 [00:01<00:10, 20.25ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 28/243 [00:01<00:09, 21.50ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 31/243 [00:01<00:09, 22.07ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 34/243 [00:01<00:09, 22.79ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 37/243 [00:01<00:08, 23.19ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 40/243 [00:01<00:08, 23.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 43/243 [00:02<00:09, 20.44ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 46/243 [00:02<00:09, 21.37ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 49/243 [00:02<00:08, 21.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██▏       | 52/243 [00:02<00:08, 22.56ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 55/243 [00:02<00:08, 22.76ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 58/243 [00:02<00:08, 22.57ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 61/243 [00:03<00:11, 15.30ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▋       | 64/243 [00:03<00:10, 16.95ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 67/243 [00:03<00:09, 18.62ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 70/243 [00:03<00:08, 19.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 73/243 [00:03<00:08, 20.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 76/243 [00:03<00:07, 21.69ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 79/243 [00:03<00:08, 19.73ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 82/243 [00:03<00:07, 20.85ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 85/243 [00:04<00:07, 21.28ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 88/243 [00:04<00:07, 21.02ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 91/243 [00:04<00:06, 21.98ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▊      | 94/243 [00:04<00:06, 22.41ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|███▉      | 97/243 [00:04<00:07, 19.91ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 100/243 [00:04<00:06, 20.93ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 103/243 [00:04<00:06, 22.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▎     | 106/243 [00:05<00:06, 22.56ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 109/243 [00:05<00:05, 23.19ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 112/243 [00:05<00:05, 23.19ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 115/243 [00:05<00:06, 19.87ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▊     | 118/243 [00:05<00:06, 20.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|████▉     | 121/243 [00:05<00:05, 21.40ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 124/243 [00:05<00:05, 22.30ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 127/243 [00:06<00:05, 22.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 130/243 [00:06<00:04, 22.93ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 133/243 [00:06<00:05, 20.06ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 136/243 [00:06<00:05, 20.96ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 139/243 [00:06<00:04, 21.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 142/243 [00:06<00:04, 22.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|█████▉    | 145/243 [00:06<00:04, 22.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 148/243 [00:06<00:04, 22.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 151/243 [00:07<00:04, 19.76ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 154/243 [00:07<00:04, 20.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 157/243 [00:07<00:03, 21.67ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 160/243 [00:07<00:03, 22.60ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 163/243 [00:07<00:03, 22.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 166/243 [00:07<00:03, 23.30ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 169/243 [00:08<00:03, 20.46ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 172/243 [00:08<00:03, 21.41ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 175/243 [00:08<00:03, 22.02ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 178/243 [00:08<00:02, 22.32ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 181/243 [00:08<00:02, 22.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 184/243 [00:08<00:02, 23.22ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 187/243 [00:08<00:02, 20.38ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 190/243 [00:08<00:02, 20.90ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 193/243 [00:09<00:02, 22.03ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 196/243 [00:09<00:02, 22.54ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 199/243 [00:09<00:01, 22.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 202/243 [00:09<00:01, 23.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 205/243 [00:09<00:01, 20.99ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 208/243 [00:09<00:01, 21.69ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 211/243 [00:09<00:01, 22.06ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 214/243 [00:10<00:01, 22.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 217/243 [00:10<00:01, 22.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 220/243 [00:10<00:01, 22.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 223/243 [00:10<00:00, 20.16ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 226/243 [00:10<00:00, 21.14ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 229/243 [00:10<00:00, 22.10ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 232/243 [00:10<00:00, 23.06ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 235/243 [00:10<00:00, 23.31ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 238/243 [00:11<00:00, 23.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 241/243 [00:11<00:00, 20.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 243/243 [00:11<00:00, 21.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/27 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-fb90e08dd36f9e4a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-12b3f3eecbd49bae.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 3/27 [00:00<00:01, 22.85ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 6/27 [00:00<00:00, 23.90ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 9/27 [00:00<00:00, 24.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 12/27 [00:00<00:00, 24.33ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 15/27 [00:00<00:00, 20.28ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 18/27 [00:00<00:00, 21.21ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 21/27 [00:00<00:00, 22.35ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 24/27 [00:01<00:00, 22.34ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 27/27 [00:01<00:00, 22.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 27/27 [00:01<00:00, 22.48ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - __main__ - Sample 167621 of the training set: {'text': '喜新厌旧啊', 'label': 5, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - __main__ - Sample 29184 of the training set: {'text': '张真源喔喔', 'label': 8, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - __main__ - Sample 6556 of the training set: {'text': '两次双黄了啊', 'label': 2, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.18.4/metrics/accuracy/accuracy.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpqiqfetvu\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.41k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 3.19kB [00:00, 3.18MB/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.18.4/metrics/accuracy/accuracy.py in cache at /root/.cache/huggingface/datasets/downloads/18ec2a1ed9dbcfd6ecff70a4f0d0d33fd5cc40c51c3c816376dc3d0b3e30219f.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\u001b[0m\n",
      "\u001b[34m05/11/2022 19:20:54 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/18ec2a1ed9dbcfd6ecff70a4f0d0d33fd5cc40c51c3c816376dc3d0b3e30219f.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\u001b[0m\n",
      "\n",
      "2022-05-11 19:21:09 Uploading - Uploading generated training model\u001b[34m[INFO|trainer.py:570] 2022-05-11 19:20:57,964 >> The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: text. If text are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:570] 2022-05-11 19:20:57,964 >> The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: text. If text are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1279] 2022-05-11 19:20:57,979 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1280] 2022-05-11 19:20:57,980 >>   Num examples = 242920\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1279] 2022-05-11 19:20:57,979 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1280] 2022-05-11 19:20:57,980 >>   Num examples = 242920\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1281] 2022-05-11 19:20:57,980 >>   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1282] 2022-05-11 19:20:57,980 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1283] 2022-05-11 19:20:57,980 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1281] 2022-05-11 19:20:57,980 >>   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1282] 2022-05-11 19:20:57,980 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1283] 2022-05-11 19:20:57,980 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1284] 2022-05-11 19:20:57,980 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1285] 2022-05-11 19:20:57,980 >>   Total optimization steps = 3796\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1284] 2022-05-11 19:20:57,980 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1285] 2022-05-11 19:20:57,980 >>   Total optimization steps = 3796\u001b[0m\n",
      "\u001b[34m0%|          | 0/3796 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.384 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.560 algo-1:26 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.561 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.561 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.562 algo-1:26 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:58.562 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.355 algo-1:26 INFO hook.py:560] name:shared.weight count_params:16449536\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.355 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.355 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.355 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.355 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.0.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.1.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.356 algo-1:26 INFO hook.py:560] name:encoder.block.2.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.3.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.4.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.357 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:encoder.block.5.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:encoder.final_layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.0.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.358 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.1.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.359 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.2.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.3.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.360 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.4.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.361 algo-1:26 INFO hook.py:560] name:decoder.block.5.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.362 algo-1:26 INFO hook.py:560] name:decoder.final_layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.362 algo-1:26 INFO hook.py:562] Total Trainable Params: 60506624\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.362 algo-1:26 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-05-11 19:20:59.363 algo-1:26 INFO hook.py:485] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[34mFile \"run_glue_t5.py\", line 591, in <module>\u001b[0m\n",
      "\u001b[34mmain()\u001b[0m\n",
      "\u001b[34mFile \"run_glue_t5.py\", line 509, in main\u001b[0m\n",
      "\u001b[34mtrain_result = trainer.train(resume_from_checkpoint=checkpoint)\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 1400, in train\u001b[0m\n",
      "\u001b[34mtr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 1984, in training_step\u001b[0m\n",
      "\u001b[34mloss = self.compute_loss(model, inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 2016, in compute_loss\u001b[0m\n",
      "\u001b[34moutputs = model(**inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1149, in _call_impl\u001b[0m\n",
      "\u001b[34mresult = forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 1635, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1149, in _call_impl\n",
      "    result = forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 933, in forward\n",
      "    batch_size, seq_length = input_shape\u001b[0m\n",
      "\u001b[34mValueError: not enough values to unpack (expected 2, got 1)\u001b[0m\n",
      "\u001b[34m0%|          | 0/3796 [00:03<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2022-05-11 19:21:02,332 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-05-11 19:21:02,333 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n",
      " 0%|          | 0/3796 [00:03<?, ?it/s]\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\"\u001b[0m\n",
      "\u001b[34m2022-05-11 19:21:02,333 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-05-11 19:21:32 Failed - Training job failed\n",
      "ProfilerReport-1652296445: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-pytorch-training-2022-05-11-19-14-04-508: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n 0%|          | 0/3796 [00:03<?, ?it/s]\"\nCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b16382994147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# starting the train job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhuggingface_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3337\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m             )\n\u001b[1;32m   3341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-pytorch-training-2022-05-11-19-14-04-508: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n 0%|          | 0/3796 [00:03<?, ?it/s]\"\nCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\", exit code: 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit({'train': train_input_path, 'test': test_input_path, 'val':val_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "66217f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '菲布理',\n",
       " 'label': 2,\n",
       " 'input_ids': [3, 2, 1],\n",
       " 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa8f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
