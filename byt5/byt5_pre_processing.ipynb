{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_lightning==0.7.5\n",
    "# !pip install transformers==2.9.0 \n",
    "# !pip install sentencepiece\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "/media/zihao/New Volume1/UMASS/685_e/github/Zihao_branch/data/Danmu_byt5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "data_path = \"/media/zihao/New Volume1/UMASS/685_e/github/Zihao_branch/data/Danmu_byt5\"\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lst = []\n",
    "\n",
    "for i in ['danmu', 'comment']:\n",
    "    with open('{}_token.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "    with open('{}_dist.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "        \n",
    "danmu_token, danmu_dist, comment_token, comment_dist = tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337392 48039\n"
     ]
    }
   ],
   "source": [
    "print(len(danmu_token), len(comment_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "print(danmu_dist[0])\n",
    "print(len(danmu_dist[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337392\n",
      "337392\n"
     ]
    }
   ],
   "source": [
    "danmu_label = []\n",
    "for i in danmu_dist:\n",
    "    #print(np.where(i==1))\n",
    "    max = i.max()\n",
    "    indexs = np.where(i==max)\n",
    "    if len(indexs) > 1:\n",
    "        print(i)\n",
    "        print(indexs)\n",
    "        break\n",
    "    # print(indexs[0])\n",
    "    # print(len(indexs[0]))\n",
    "    danmu_label.append(indexs[0][0])\n",
    "    \n",
    "print(len(danmu_label))\n",
    "print(len(danmu_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 124}\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "#not every class have associated data(danmu)\n",
    "print(set(danmu_label))\n",
    "print(len(set(danmu_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "132683\n"
     ]
    }
   ],
   "source": [
    "print(type(danmu_token))\n",
    "random_index = random.randrange(len(danmu_token))\n",
    "\n",
    "print(random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 337392)\n",
      "269913\n"
     ]
    }
   ],
   "source": [
    "sort_indexs = range(0, len(danmu_token))\n",
    "print(sort_indexs)\n",
    "num = int(len(danmu_dist)*0.8)\n",
    "print(num)\n",
    "selected_indexs = random.sample(sort_indexs,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269913 67479\n"
     ]
    }
   ],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "train_label = []\n",
    "test_label = []\n",
    "for ind, token in enumerate(danmu_token):\n",
    "    if ind in selected_indexs:\n",
    "        train_set.append(token)\n",
    "        train_label.append(danmu_label[ind])\n",
    "    else:\n",
    "        test_set.append(token)\n",
    "        test_label.append(danmu_label[ind])\n",
    "print(len(train_set),len(test_set))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269913\n",
      "269913\n",
      "67479\n",
      "67479\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(train_label))\n",
    "print(len(test_set))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 67479)\n",
      "33739\n"
     ]
    }
   ],
   "source": [
    "sort_indexs = range(0, len(test_set))\n",
    "print(sort_indexs)\n",
    "num = int(len(test_set)*0.5)\n",
    "print(num)\n",
    "selected_indexs_val = random.sample(sort_indexs,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_set = []\n",
    "test_new_label = []\n",
    "val_set = []\n",
    "val_label = []\n",
    "for ind, token in enumerate(test_set):\n",
    "    if ind in selected_indexs_val:\n",
    "        test_new_set.append(token)\n",
    "        test_new_label.append(test_label[ind])\n",
    "    else:\n",
    "        val_set.append(token)\n",
    "        val_label.append(test_label[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_new_set\n",
    "test_label = test_new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_path+\"/pkl/\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'train/danmu_token_single_label_train.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(train_set,f)\n",
    "with open(data_path+'train/danmu_dist_single_label_train.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(train_label,f)\n",
    "    \n",
    "with open(data_path+'test/danmu_token_single_label_test.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(test_set,f)\n",
    "with open(data_path+'test/danmu_dist_single_label_test.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(test_label,f)\n",
    "\n",
    "with open(data_path+'val/danmu_token_single_label_val.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(val_set,f)\n",
    "with open(data_path+'val/danmu_dist_single_label_val.pkl'.format(i), 'wb') as f:\n",
    "    pickle.dump(val_set,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无能狂怒\n",
      "1人在观看\n",
      "269913\n",
      "33739\n",
      "33740\n"
     ]
    }
   ],
   "source": [
    "with open(data_path + 'train/danmu_token_single_label_train.pkl', 'rb') as f:\n",
    "    train_pkl = pickle.load(f)\n",
    "with open(data_path + 'test/danmu_token_single_label_test.pkl', 'rb') as f:\n",
    "    test_pkl = pickle.load(f)\n",
    "with open(data_path + 'val/danmu_token_single_label_val.pkl', 'rb') as f:\n",
    "    val_pkl = pickle.load(f)\n",
    "print(train_pkl[0])\n",
    "print(danmu_token[0])\n",
    "print(len(train_pkl))\n",
    "print(len(test_pkl))\n",
    "print(len(val_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data to pkl file without separating training or testing\n",
    "\n",
    "# with open('danmu_token_single_label.pkl'.format(i), 'wb') as f:\n",
    "#     # for danmu in danmu_token:\n",
    "#     #     pickle.dump(danmu, f)\n",
    "#     pickle.dump(danmu_token,f)\n",
    "# with open('danmu_dist_single_label.pkl'.format(i), 'wb') as f:\n",
    "#     pickle.dump(danmu_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(danmu_token))\n",
    "# for ind, label in enumerate(danmu_label):\n",
    "#     branch = ''\n",
    "#     if ind in selected_indexs:\n",
    "#         branch = 'train'\n",
    "#     else:\n",
    "#         branch = 'test'\n",
    "#     path = data_path+\"/\"+branch+\"/\"+str(label)\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "#     file_name = str(datetime.datetime.now().strftime(\"%H_%M_%S_%f\")) + '.txt'\n",
    "#     with open(path+'/'+file_name, 'w+') as f:\n",
    "#         f.write(danmu_token[ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81fddcebdcddcb9bd173b56375a42ed7b9a2836b109af7b71e91152a3d8ca675"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
