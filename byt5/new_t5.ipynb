{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3ec009",
   "metadata": {},
   "source": [
    "# Get Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a919b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996218a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\gdown\\cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hTp8qDF4r2tTk7W6SBnfYyRoNwwSdkap\n",
      "To: e:\\UMASS\\685_e\\github\\Zihao_branch\\bilimemenet\\danmu_token_main.pkl\n",
      "\n",
      "  0%|          | 0.00/5.38M [00:00<?, ?B/s]\n",
      " 10%|▉         | 524k/5.38M [00:00<00:01, 4.68MB/s]\n",
      " 29%|██▉       | 1.57M/5.38M [00:00<00:00, 5.02MB/s]\n",
      " 39%|███▉      | 2.10M/5.38M [00:00<00:00, 5.00MB/s]\n",
      " 58%|█████▊    | 3.15M/5.38M [00:00<00:00, 5.25MB/s]\n",
      " 68%|██████▊   | 3.67M/5.38M [00:00<00:00, 5.13MB/s]\n",
      " 78%|███████▊  | 4.19M/5.38M [00:00<00:00, 5.08MB/s]\n",
      " 97%|█████████▋| 5.24M/5.38M [00:01<00:00, 5.17MB/s]\n",
      "100%|██████████| 5.38M/5.38M [00:01<00:00, 5.15MB/s]\n",
      "E:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\gdown\\cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1T-yZGWyPC89SCCbm1m0DrRMGyDlUaonl\n",
      "To: e:\\UMASS\\685_e\\github\\Zihao_branch\\bilimemenet\\danmu_dist_main.pkl\n",
      "\n",
      "  0%|          | 0.00/56.7M [00:00<?, ?B/s]\n",
      "  2%|▏         | 1.05M/56.7M [00:00<00:10, 5.35MB/s]\n",
      "  4%|▎         | 2.10M/56.7M [00:00<00:10, 5.31MB/s]\n",
      "  6%|▌         | 3.15M/56.7M [00:00<00:10, 5.17MB/s]\n",
      "  6%|▋         | 3.67M/56.7M [00:00<00:10, 4.98MB/s]\n",
      "  7%|▋         | 4.19M/56.7M [00:00<00:10, 4.85MB/s]\n",
      "  8%|▊         | 4.72M/56.7M [00:00<00:10, 4.95MB/s]\n",
      "  9%|▉         | 5.24M/56.7M [00:01<00:11, 4.58MB/s]\n",
      " 10%|█         | 5.77M/56.7M [00:01<00:11, 4.54MB/s]\n",
      " 11%|█         | 6.29M/56.7M [00:01<00:10, 4.63MB/s]\n",
      " 12%|█▏        | 6.82M/56.7M [00:01<00:10, 4.68MB/s]\n",
      " 13%|█▎        | 7.34M/56.7M [00:01<00:10, 4.56MB/s]\n",
      " 14%|█▍        | 7.86M/56.7M [00:01<00:11, 4.43MB/s]\n",
      " 15%|█▍        | 8.39M/56.7M [00:01<00:10, 4.61MB/s]\n",
      " 17%|█▋        | 9.44M/56.7M [00:01<00:09, 4.95MB/s]\n",
      " 18%|█▊        | 10.5M/56.7M [00:02<00:09, 5.08MB/s]\n",
      " 20%|██        | 11.5M/56.7M [00:02<00:08, 5.13MB/s]\n",
      " 22%|██▏       | 12.6M/56.7M [00:02<00:08, 5.23MB/s]\n",
      " 24%|██▍       | 13.6M/56.7M [00:02<00:08, 5.21MB/s]\n",
      " 26%|██▌       | 14.7M/56.7M [00:02<00:08, 5.23MB/s]\n",
      " 28%|██▊       | 15.7M/56.7M [00:03<00:07, 5.35MB/s]\n",
      " 30%|██▉       | 16.8M/56.7M [00:03<00:07, 5.37MB/s]\n",
      " 31%|███▏      | 17.8M/56.7M [00:03<00:07, 5.42MB/s]\n",
      " 33%|███▎      | 18.9M/56.7M [00:03<00:07, 5.29MB/s]\n",
      " 35%|███▌      | 19.9M/56.7M [00:03<00:06, 5.33MB/s]\n",
      " 37%|███▋      | 21.0M/56.7M [00:04<00:06, 5.38MB/s]\n",
      " 39%|███▉      | 22.0M/56.7M [00:04<00:06, 5.35MB/s]\n",
      " 41%|████      | 23.1M/56.7M [00:04<00:06, 5.39MB/s]\n",
      " 43%|████▎     | 24.1M/56.7M [00:04<00:06, 5.42MB/s]\n",
      " 44%|████▍     | 25.2M/56.7M [00:04<00:05, 5.35MB/s]\n",
      " 46%|████▌     | 26.2M/56.7M [00:05<00:05, 5.39MB/s]\n",
      " 48%|████▊     | 27.3M/56.7M [00:05<00:05, 5.35MB/s]\n",
      " 50%|████▉     | 28.3M/56.7M [00:05<00:05, 5.37MB/s]\n",
      " 52%|█████▏    | 29.4M/56.7M [00:05<00:05, 5.32MB/s]\n",
      " 54%|█████▎    | 30.4M/56.7M [00:05<00:05, 5.25MB/s]\n",
      " 55%|█████▌    | 31.5M/56.7M [00:06<00:04, 5.33MB/s]\n",
      " 57%|█████▋    | 32.5M/56.7M [00:06<00:04, 5.06MB/s]\n",
      " 59%|█████▉    | 33.6M/56.7M [00:06<00:04, 5.16MB/s]\n",
      " 61%|██████    | 34.6M/56.7M [00:06<00:04, 5.23MB/s]\n",
      " 63%|██████▎   | 35.7M/56.7M [00:06<00:04, 5.17MB/s]\n",
      " 64%|██████▍   | 36.2M/56.7M [00:07<00:03, 5.17MB/s]\n",
      " 65%|██████▍   | 36.7M/56.7M [00:07<00:03, 5.18MB/s]\n",
      " 67%|██████▋   | 37.7M/56.7M [00:07<00:03, 5.23MB/s]\n",
      " 68%|██████▊   | 38.8M/56.7M [00:07<00:03, 5.30MB/s]\n",
      " 70%|███████   | 39.8M/56.7M [00:07<00:03, 5.31MB/s]\n",
      " 72%|███████▏  | 40.9M/56.7M [00:07<00:03, 5.26MB/s]\n",
      " 74%|███████▍  | 41.9M/56.7M [00:08<00:02, 5.36MB/s]\n",
      " 76%|███████▌  | 43.0M/56.7M [00:08<00:02, 5.22MB/s]\n",
      " 78%|███████▊  | 44.0M/56.7M [00:08<00:02, 5.26MB/s]\n",
      " 80%|███████▉  | 45.1M/56.7M [00:08<00:02, 5.28MB/s]\n",
      " 81%|████████▏ | 46.1M/56.7M [00:08<00:02, 5.23MB/s]\n",
      " 83%|████████▎ | 47.2M/56.7M [00:09<00:01, 5.32MB/s]\n",
      " 85%|████████▌ | 48.2M/56.7M [00:09<00:01, 5.28MB/s]\n",
      " 87%|████████▋ | 49.3M/56.7M [00:09<00:01, 4.65MB/s]\n",
      " 88%|████████▊ | 49.8M/56.7M [00:09<00:01, 4.71MB/s]\n",
      " 89%|████████▉ | 50.3M/56.7M [00:09<00:01, 4.75MB/s]\n",
      " 91%|█████████ | 51.4M/56.7M [00:09<00:01, 5.00MB/s]\n",
      " 92%|█████████▏| 52.4M/56.7M [00:10<00:00, 5.16MB/s]\n",
      " 94%|█████████▍| 53.5M/56.7M [00:10<00:00, 5.20MB/s]\n",
      " 96%|█████████▌| 54.5M/56.7M [00:10<00:00, 5.29MB/s]\n",
      " 98%|█████████▊| 55.6M/56.7M [00:10<00:00, 5.27MB/s]\n",
      "100%|█████████▉| 56.6M/56.7M [00:10<00:00, 5.31MB/s]\n",
      "100%|██████████| 56.7M/56.7M [00:10<00:00, 5.17MB/s]\n"
     ]
    }
   ],
   "source": [
    "#https://drive.google.com/file/d/1hTp8qDF4r2tTk7W6SBnfYyRoNwwSdkap/view?usp=sharing\n",
    "!gdown --id 1hTp8qDF4r2tTk7W6SBnfYyRoNwwSdkap\n",
    "#https://drive.google.com/file/d/1T-yZGWyPC89SCCbm1m0DrRMGyDlUaonl/view?usp=sharing\n",
    "!gdown --id 1T-yZGWyPC89SCCbm1m0DrRMGyDlUaonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497c7b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337392\n",
      "337392\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "token_file = open(\"danmu_token_main.pkl\", \"rb\")\n",
    "dist_file = open(\"danmu_dist_main.pkl\", \"rb\")\n",
    "\n",
    "tokens = pickle.load(token_file)\n",
    "dists = pickle.load(dist_file)\n",
    "\n",
    "print(len(tokens))\n",
    "print(len(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5959d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = [np.argmax(i) for i in dists]\n",
    "\n",
    "label_distribution = {}\n",
    "for i in labels:\n",
    "    if i in label_distribution:\n",
    "        label_distribution[i] += 1\n",
    "    else:\n",
    "        label_distribution[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce78fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label with no data\n",
    "label_list = list(label_distribution.keys())\n",
    "labels = [label_list.index(i) for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8f368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.DataFrame({\n",
    "    'text': tokens,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13775518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging\n",
    "train_df = train_df[train_df['text'] != 'nan']\n",
    "test_df = test_df[test_df['text'] != 'nan']\n",
    "val_df = val_df[val_df['text'] != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bdca89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>张张一身正气</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>双开yyds</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>朱志鑫憨憨的</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>初三了</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>男主挺帅</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26987</th>\n",
       "      <td>刻晴球球</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26988</th>\n",
       "      <td>人皇笔</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26989</th>\n",
       "      <td>对对对胡萝北</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26990</th>\n",
       "      <td>时间真快啊</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26991</th>\n",
       "      <td>大佬不要谦虚</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  label\n",
       "0      张张一身正气      8\n",
       "1      双开yyds      2\n",
       "2      朱志鑫憨憨的      8\n",
       "3         初三了      4\n",
       "4        男主挺帅     10\n",
       "...       ...    ...\n",
       "26987    刻晴球球     15\n",
       "26988     人皇笔      4\n",
       "26989  对对对胡萝北      1\n",
       "26990   时间真快啊      4\n",
       "26991  大佬不要谦虚      7\n",
       "\n",
       "[26992 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.reset_index(drop=True)\n",
    "test_df.reset_index(drop=True)\n",
    "val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422c548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a25be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "\n",
    "train_df.to_csv('data_csv/train.csv', index = False)\n",
    "test_df.to_csv('data_csv/test.csv', index = False)\n",
    "val_df.to_csv('data_csv/val.csv', index = False)\n",
    "\n",
    "# train_dict = train_df.to_dict()\n",
    "# test_dict = test_df.to_dict()\n",
    "# val_dict = val_df.to_dict()\n",
    "# train_data_json = {\n",
    "#     'train' : train_dict,\n",
    "#     'test' : test_dict,\n",
    "#     'validation': val_dict\n",
    "# }\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open('data_csv/data.json', 'w') as f:\n",
    "#     json.dump(train_data_json, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962641e",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b3e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "train = datasets.Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val = datasets.Dataset.from_pandas(val_df, preserve_index=False)\n",
    "test = datasets.Dataset.from_pandas(test_df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6de1f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to C:\\Users\\leima\\.cache\\huggingface\\transformers\\tmpazhj3qdh\n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 29.0kB/s]\n",
      "storing https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json in cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "creating metadata file for C:\\Users\\leima/.cache\\huggingface\\transformers\\2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "https://huggingface.co/bert-base-chinese/resolve/main/config.json not found in cache or force_download set to True, downloading to C:\\Users\\leima\\.cache\\huggingface\\transformers\\tmp3632_fhy\n",
      "Downloading: 100%|██████████| 624/624 [00:00<00:00, 624kB/s]\n",
      "storing https://huggingface.co/bert-base-chinese/resolve/main/config.json in cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "creating metadata file for C:\\Users\\leima/.cache\\huggingface\\transformers\\6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to C:\\Users\\leima\\.cache\\huggingface\\transformers\\tmplsmqidmx\n",
      "Downloading: 100%|██████████| 107k/107k [00:00<00:00, 2.04MB/s]\n",
      "storing https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt in cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
      "creating metadata file for C:\\Users\\leima/.cache\\huggingface\\transformers\\36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
      "https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to C:\\Users\\leima\\.cache\\huggingface\\transformers\\tmpxe7wi8ut\n",
      "Downloading: 100%|██████████| 263k/263k [00:00<00:00, 2.60MB/s]\n",
      "storing https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json in cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
      "creating metadata file for C:\\Users\\leima/.cache\\huggingface\\transformers\\7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffb9e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  0%|          | 0/9375 [5:02:31<?, ?it/s]\n",
      "  0%|          | 0/9375 [4:52:32<?, ?it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 243/243 [00:06<00:00, 35.85ba/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 43.10ba/s]\n",
      "100%|██████████| 68/68 [00:01<00:00, 42.88ba/s]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "tokenized_train =  train.map(preprocess_function, batched=True)\n",
    "tokenized_val =  val.map(preprocess_function, batched=True)\n",
    "tokenized_test = test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf853892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For batching and padding\n",
    "import transformers \n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc2e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e548b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\leima\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.67it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.75ba/s]\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.91ba/s]\n",
      "100%|██████████| 50/50 [00:26<00:00,  1.86ba/s]\n"
     ]
    }
   ],
   "source": [
    "#test with imdb\n",
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac892616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df7a64",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ea425ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/uer/roberta-base-finetuned-chinanews-chinese/resolve/main/config.json from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\af4b6c96febdc688b8005efcb145154016ef204fd3e3cae0cf4d915a16eda5c9.7692f4bdefb5ffde1d234ea8bef51cee40d64e5d1cbac9b5e45507181b11da38\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"uer/roberta-base-finetuned-chinanews-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/uer/roberta-base-finetuned-chinanews-chinese/resolve/main/pytorch_model.bin from cache at C:\\Users\\leima/.cache\\huggingface\\transformers\\a7f70367560bf2c68ea260d780c103cbf2d12afd1edd48b6861d495ceaea3880.b5d481b84b8ddf012a0173bf5d7eb9e52acea0ccd8c01edd4417906601050d78\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([19, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([19]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2732\\1135373653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m model = transformers.AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-chinanews-chinese\",\\\n\u001b[0;32m      4\u001b[0m                                                                         \u001b[0mproblem_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"multi_label_classification\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                                                          num_labels = len(label_distribution))\n\u001b[0m\u001b[0;32m      6\u001b[0m                                                                     \u001b[1;31m#    ignore_mismatched_sizes=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         raise ValueError(\n\u001b[0;32m    449\u001b[0m             \u001b[1;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m                     \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_mismatched_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m                     \u001b[0m_fast_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m                 )\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(cls, model, state_dict, pretrained_model_name_or_path, ignore_mismatched_sizes, _fast_init)\u001b[0m\n\u001b[0;32m   1688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n\\t\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([19, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([19])."
     ]
    }
   ],
   "source": [
    "num_labels = len(model.config.id2label)\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-chinanews-chinese\",\\\n",
    "                                                                        problem_type=\"multi_label_classification\",\\\n",
    "                                                                         num_labels = len(label_distribution))\n",
    "                                                                    #    ignore_mismatched_sizes=True)\n",
    "\n",
    "training_args = transformers.TrainingArguments(output_dir=\"roberta_chinese_ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7ecd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90e67e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_imdb['train'], # tokenized_train,\n",
    "    eval_dataset = tokenized_imdb['test'], #tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1e64d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9375\n",
      "\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (616) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [8, 616].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2732\\4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1400\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m                 if (\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1984\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1986\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2016\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1552\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1554\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1555\u001b[0m         )\n\u001b[0;32m   1556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Program_Files\\Anaconda\\envs\\685_final\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (616) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [8, 616].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982418f",
   "metadata": {},
   "source": [
    "# SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6f1d5723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: arn:aws:iam::635837196364:role/service-role/AmazonSageMaker-ExecutionRole-20220427T210117\n",
      "bucket: sagemaker-us-east-1-635837196364\n",
      "session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "session_bucket = None\n",
    "if session_bucket == None and session is not None:\n",
    "    session_bucket = session.default_bucket()\n",
    "    \n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session(default_bucket = session_bucket)\n",
    "\n",
    "print(f'role: {role}')\n",
    "print(f'bucket: {session_bucket}')\n",
    "print(f'session region: {session.boto_region_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2df7da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_train\n",
    "test_dataset = datasets.concatenate_datasets([tokenized_val, tokenized_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6405e",
   "metadata": {},
   "source": [
    "Upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "42efc764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-635837196364/dataset/danmu_main/val/val.csv'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = 'dataset/danmu_main'\n",
    "\n",
    "#save data to S3\n",
    "train_input_path = f's3://{session.default_bucket()}/{s3_prefix}/train'\n",
    "#train_dataset.save_to_disk(train_input_path, fs = s3)\n",
    "session.upload_data(path='data_csv/train.csv', bucket=session_bucket, key_prefix=s3_prefix+'/train')\n",
    "\n",
    "test_input_path = f's3://{session.default_bucket()}/{s3_prefix}/test'\n",
    "#test_dataset.save_to_disk(test_input_path, fs = s3)\n",
    "session.upload_data(path='data_csv/test.csv', bucket=session_bucket, key_prefix=s3_prefix+'/test')\n",
    "\n",
    "val_input_path = f's3://{session.default_bucket()}/{s3_prefix}/val'\n",
    "session.upload_data(path='data_csv/val.csv', bucket=session_bucket, key_prefix=s3_prefix+'/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a346eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# gets role for executing training job\n",
    "\n",
    "hyperparameters = {\n",
    "    'model_name_or_path':'t5-small',\n",
    "    'output_dir':'/opt/ml/model/t5_small',\n",
    "    # add your remaining hyperparameters \n",
    "    # more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/text-classification\n",
    "    'max_seq_length':128,\n",
    "    'per_device_train_batch_size' : 64,\n",
    "    'learning_rate' : 2e-5,\n",
    "    'num_train_epochs': 1,\n",
    "    #train\n",
    "    'do_train': True,\n",
    "    #data\n",
    "    'train_file': '/opt/ml/input/data/train/train.csv',\n",
    "    #'test_file': '/opt/ml/input/data/train/test.csv',\n",
    "    'validation_file': '/opt/ml/input/data/val/val.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "477542fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_glue_t5.py',\n",
    "    #source_dir='./examples/pytorch/text-classification',\n",
    "    source_dir = './scripts',\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    #it_config=git_config,\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    hyperparameters = hyperparameters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c3f4ead3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 11:24:29 Starting - Starting the training job...\n",
      "2022-05-11 11:24:57 Starting - Preparing the instances for trainingProfilerReport-1652268269: InProgress\n",
      ".........\n",
      "2022-05-11 11:26:18 Downloading - Downloading input data...\n",
      "2022-05-11 11:26:54 Training - Downloading the training image........................\n",
      "2022-05-11 11:30:55 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-11 11:30:57,960 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-11 11:30:57,978 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-11 11:30:57,985 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-11 11:30:58,455 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"do_train\": true,\n",
      "        \"learning_rate\": 2e-05,\n",
      "        \"max_seq_length\": 128,\n",
      "        \"model_name_or_path\": \"t5-small\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/opt/ml/model/t5_small\",\n",
      "        \"per_device_train_batch_size\": 64,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/train.csv\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/val/val.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-05-11-11-24-29-437\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-11-24-29-437/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_glue_t5\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_glue_t5.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"do_train\":true,\"learning_rate\":2e-05,\"max_seq_length\":128,\"model_name_or_path\":\"t5-small\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model/t5_small\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"validation_file\":\"/opt/ml/input/data/val/val.csv\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_glue_t5.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_glue_t5\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-11-24-29-437/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"do_train\":true,\"learning_rate\":2e-05,\"max_seq_length\":128,\"model_name_or_path\":\"t5-small\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model/t5_small\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"validation_file\":\"/opt/ml/input/data/val/val.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2022-05-11-11-24-29-437\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-635837196364/huggingface-pytorch-training-2022-05-11-11-24-29-437/source/sourcedir.tar.gz\",\"module_name\":\"run_glue_t5\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_glue_t5.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--do_train\",\"True\",\"--learning_rate\",\"2e-05\",\"--max_seq_length\",\"128\",\"--model_name_or_path\",\"t5-small\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/opt/ml/model/t5_small\",\"--per_device_train_batch_size\",\"64\",\"--train_file\",\"/opt/ml/input/data/train/train.csv\",\"--validation_file\",\"/opt/ml/input/data/val/val.csv\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=t5-small\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model/t5_small\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=/opt/ml/input/data/train/train.csv\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FILE=/opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/urllib3-1.26.8-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdo_eval=False,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=IntervalStrategy.NO,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_strategy=HubStrategy.EVERY_SAVE,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=2e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=-1,\u001b[0m\n",
      "\u001b[34mlog_level_replica=-1,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/t5_small/runs/May11_11-31-03_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=SchedulerType.LINEAR,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=1.0,\u001b[0m\n",
      "\u001b[34moptim=OptimizerNames.ADAMW_HF,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model/t5_small,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=64,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model/t5_small,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=IntervalStrategy.STEPS,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - __main__ - load a local file for train: /opt/ml/input/data/train/train.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - __main__ - load a local file for validation: /opt/ml/input/data/val/val.csv\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - WARNING - datasets.builder - Using custom data configuration default-7cc92f2d52f113db\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.builder - Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-7cc92f2d52f113db/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-7cc92f2d52f113db/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 8895.66it/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 2163.13it/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.utils.info_utils - Unable to verify checksums.\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.builder - Generating split train\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.builder - Generating split validation\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:03 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-7cc92f2d52f113db/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:00<00:00, 403.78it/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:03,990 >> https://huggingface.co/t5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpo15bc3nf\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:03,990 >> https://huggingface.co/t5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpo15bc3nf\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 1.17k/1.17k [00:00<00:00, 1.60MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,023 >> storing https://huggingface.co/t5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,023 >> creating metadata file for /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,023 >> storing https://huggingface.co/t5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,023 >> creating metadata file for /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,023 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,023 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,024 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,024 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:344] 2022-05-11 11:31:04,058 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:344] 2022-05-11 11:31:04,058 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,093 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,093 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,094 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,094 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,162 >> https://huggingface.co/t5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqbtcj7xc\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,162 >> https://huggingface.co/t5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqbtcj7xc\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/773k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 773k/773k [00:00<00:00, 34.2MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,229 >> storing https://huggingface.co/t5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,229 >> creating metadata file for /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,229 >> storing https://huggingface.co/t5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,229 >> creating metadata file for /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,259 >> https://huggingface.co/t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp73etzg76\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,259 >> https://huggingface.co/t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp73etzg76\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 1.32M/1.32M [00:00<00:00, 22.0MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,407 >> storing https://huggingface.co/t5-small/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:04,407 >> storing https://huggingface.co/t5-small/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,408 >> creating metadata file for /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:04,408 >> creating metadata file for /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,539 >> loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,539 >> loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1786] 2022-05-11 11:31:04,540 >> loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,570 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:648] 2022-05-11 11:31:04,570 >> loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,571 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:684] 2022-05-11 11:31:04,571 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,674 >> https://huggingface.co/t5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpztzkoqv9\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2215] 2022-05-11 11:31:04,674 >> https://huggingface.co/t5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpztzkoqv9\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/231M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   3%|▎         | 6.23M/231M [00:00<00:03, 65.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   5%|▌         | 12.5M/231M [00:00<00:03, 63.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 19.1M/231M [00:00<00:03, 66.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█         | 25.7M/231M [00:00<00:03, 67.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▍        | 32.7M/231M [00:00<00:02, 69.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  17%|█▋        | 39.4M/231M [00:00<00:02, 69.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  20%|██        | 46.4M/231M [00:00<00:02, 71.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 54.0M/231M [00:00<00:02, 73.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▋       | 61.0M/231M [00:00<00:02, 73.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  29%|██▉       | 68.0M/231M [00:01<00:02, 72.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  32%|███▏      | 74.9M/231M [00:01<00:02, 72.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  36%|███▌      | 82.2M/231M [00:01<00:02, 73.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  39%|███▊      | 89.2M/231M [00:01<00:02, 73.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 96.2M/231M [00:01<00:01, 71.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▍     | 103M/231M [00:01<00:01, 71.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  48%|████▊     | 110M/231M [00:01<00:02, 54.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  50%|█████     | 116M/231M [00:01<00:02, 58.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▎    | 124M/231M [00:01<00:01, 62.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  57%|█████▋    | 131M/231M [00:02<00:01, 65.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  60%|█████▉    | 138M/231M [00:02<00:01, 67.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  63%|██████▎   | 145M/231M [00:02<00:01, 69.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▌   | 152M/231M [00:02<00:01, 71.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▉   | 159M/231M [00:02<00:01, 71.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  72%|███████▏  | 166M/231M [00:02<00:00, 71.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  75%|███████▍  | 173M/231M [00:02<00:00, 70.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  78%|███████▊  | 180M/231M [00:02<00:00, 72.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████  | 187M/231M [00:02<00:00, 72.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  84%|████████▍ | 195M/231M [00:02<00:00, 75.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  87%|████████▋ | 202M/231M [00:03<00:00, 74.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 209M/231M [00:03<00:00, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  94%|█████████▍| 217M/231M [00:03<00:00, 75.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  97%|█████████▋| 224M/231M [00:03<00:00, 74.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 231M/231M [00:03<00:00, 70.5MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:08,139 >> storing https://huggingface.co/t5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:08,139 >> creating metadata file for /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2219] 2022-05-11 11:31:08,139 >> storing https://huggingface.co/t5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|file_utils.py:2227] 2022-05-11 11:31:08,139 >> creating metadata file for /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1431] 2022-05-11 11:31:08,139 >> loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1431] 2022-05-11 11:31:08,139 >> loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1702] 2022-05-11 11:31:08,916 >> All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1704] 2022-05-11 11:31:08,917 >> Some weights of MT5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['lm_head.weight', 'decoder.embed_tokens.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1702] 2022-05-11 11:31:08,916 >> All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:1704] 2022-05-11 11:31:08,917 >> Some weights of MT5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['lm_head.weight', 'decoder.embed_tokens.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/243 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7cc92f2d52f113db/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-01f638fea6514df8.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 1/243 [00:00<00:26,  9.21ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 4/243 [00:00<00:16, 14.32ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 7/243 [00:00<00:12, 18.79ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 10/243 [00:00<00:11, 21.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 13/243 [00:00<00:10, 22.11ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 16/243 [00:00<00:10, 22.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 19/243 [00:00<00:09, 23.24ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 22/243 [00:01<00:09, 23.86ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 25/243 [00:01<00:10, 20.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 28/243 [00:01<00:09, 21.80ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 31/243 [00:01<00:09, 22.13ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 34/243 [00:01<00:09, 22.73ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 37/243 [00:01<00:08, 23.47ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▋        | 40/243 [00:01<00:08, 23.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 43/243 [00:02<00:09, 21.12ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 46/243 [00:02<00:09, 21.70ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 49/243 [00:02<00:08, 22.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██▏       | 52/243 [00:02<00:08, 22.90ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 55/243 [00:02<00:08, 23.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 58/243 [00:02<00:08, 22.48ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 61/243 [00:02<00:09, 20.20ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▋       | 64/243 [00:02<00:08, 21.15ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 67/243 [00:03<00:08, 21.90ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 70/243 [00:03<00:07, 22.93ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 73/243 [00:03<00:07, 23.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 76/243 [00:03<00:07, 23.16ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 79/243 [00:03<00:08, 20.24ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▎      | 82/243 [00:03<00:07, 21.57ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 85/243 [00:03<00:07, 22.05ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 88/243 [00:04<00:06, 22.23ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 91/243 [00:04<00:06, 22.47ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▊      | 94/243 [00:04<00:06, 22.91ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|███▉      | 97/243 [00:04<00:07, 20.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 100/243 [00:04<00:06, 21.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 103/243 [00:04<00:06, 22.54ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▎     | 106/243 [00:04<00:06, 22.52ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 109/243 [00:04<00:05, 23.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 112/243 [00:05<00:05, 23.38ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 115/243 [00:05<00:06, 20.85ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▊     | 118/243 [00:05<00:05, 21.56ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|████▉     | 121/243 [00:05<00:05, 22.32ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 124/243 [00:05<00:05, 22.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 127/243 [00:05<00:05, 22.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 130/243 [00:05<00:04, 23.10ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▍    | 133/243 [00:06<00:05, 20.11ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 136/243 [00:06<00:05, 21.08ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 139/243 [00:06<00:04, 21.91ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 142/243 [00:06<00:04, 22.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|█████▉    | 145/243 [00:06<00:04, 22.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 148/243 [00:06<00:04, 23.25ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 151/243 [00:06<00:04, 20.57ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 154/243 [00:07<00:04, 21.60ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▍   | 157/243 [00:07<00:03, 22.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 160/243 [00:07<00:03, 23.06ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 163/243 [00:07<00:03, 23.47ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 166/243 [00:07<00:03, 23.29ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 169/243 [00:07<00:03, 20.57ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 172/243 [00:07<00:03, 21.18ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 175/243 [00:07<00:03, 21.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 178/243 [00:08<00:02, 22.37ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 181/243 [00:08<00:02, 22.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 184/243 [00:08<00:02, 23.20ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 187/243 [00:08<00:02, 20.55ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 190/243 [00:08<00:02, 21.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 193/243 [00:08<00:02, 22.22ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████  | 196/243 [00:08<00:02, 22.87ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 199/243 [00:09<00:01, 22.10ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 202/243 [00:09<00:01, 22.65ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 205/243 [00:09<00:01, 19.86ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 208/243 [00:09<00:01, 21.05ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 211/243 [00:09<00:01, 21.38ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 214/243 [00:09<00:01, 22.01ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 217/243 [00:09<00:01, 22.17ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 220/243 [00:10<00:01, 22.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 223/243 [00:10<00:00, 20.18ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 226/243 [00:10<00:00, 20.98ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 229/243 [00:10<00:00, 22.16ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▌| 232/243 [00:10<00:00, 23.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 235/243 [00:10<00:00, 23.52ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 238/243 [00:10<00:00, 23.93ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 241/243 [00:10<00:00, 20.87ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 243/243 [00:11<00:00, 21.95ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/27 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7cc92f2d52f113db/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-de0a2f11b1d06e3d.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 3/27 [00:00<00:01, 23.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 6/27 [00:00<00:00, 23.10ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 9/27 [00:00<00:00, 22.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 12/27 [00:00<00:00, 23.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▌    | 15/27 [00:00<00:00, 19.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 18/27 [00:00<00:00, 20.96ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 21/27 [00:00<00:00, 22.03ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 24/27 [00:01<00:00, 23.00ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 27/27 [00:01<00:00, 23.91ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 27/27 [00:01<00:00, 22.66ba/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - __main__ - Sample 167621 of the training set: {'text': '到蜉蝣了', 'label': 3, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - __main__ - Sample 29184 of the training set: {'text': '我刑了', 'label': 12, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - __main__ - Sample 6556 of the training set: {'text': '这不王', 'label': 10, 'input_ids': [3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.18.4/metrics/accuracy/accuracy.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp9yu1ionv\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/1.41k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 3.19kB [00:00, 2.99MB/s]\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.18.4/metrics/accuracy/accuracy.py in cache at /root/.cache/huggingface/datasets/downloads/18ec2a1ed9dbcfd6ecff70a4f0d0d33fd5cc40c51c3c816376dc3d0b3e30219f.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\u001b[0m\n",
      "\u001b[34m05/11/2022 11:31:21 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/18ec2a1ed9dbcfd6ecff70a4f0d0d33fd5cc40c51c3c816376dc3d0b3e30219f.6913c0dc30de3cef9d6bc88cc182661800cb937f0fe5b01ffa731617105a32ac.py\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:570] 2022-05-11 11:31:24,510 >> The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: text. If text are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:570] 2022-05-11 11:31:24,510 >> The following columns in the training set  don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: text. If text are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1279] 2022-05-11 11:31:24,524 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1279] 2022-05-11 11:31:24,524 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1280] 2022-05-11 11:31:24,524 >>   Num examples = 242920\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1281] 2022-05-11 11:31:24,524 >>   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1280] 2022-05-11 11:31:24,524 >>   Num examples = 242920\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1281] 2022-05-11 11:31:24,524 >>   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1282] 2022-05-11 11:31:24,524 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1282] 2022-05-11 11:31:24,524 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1283] 2022-05-11 11:31:24,524 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1284] 2022-05-11 11:31:24,524 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1285] 2022-05-11 11:31:24,524 >>   Total optimization steps = 3796\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1283] 2022-05-11 11:31:24,524 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1284] 2022-05-11 11:31:24,524 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1285] 2022-05-11 11:31:24,524 >>   Total optimization steps = 3796\u001b[0m\n",
      "\u001b[34m0%|          | 0/3796 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:24.858 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.024 algo-1:27 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.025 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.026 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.026 algo-1:27 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.026 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.802 algo-1:27 INFO hook.py:560] name:shared.weight count_params:16449536\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.0.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.1.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.803 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.2.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.3.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.804 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.4.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.1.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.1.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.block.5.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:encoder.final_layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.805 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.0.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.1.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.806 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.2.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.807 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.3.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.4.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.0.SelfAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.0.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.808 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.q.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.k.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.v.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.1.EncDecAttention.o.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.1.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.2.DenseReluDense.wi.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.2.DenseReluDense.wo.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.block.5.layer.2.layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:560] name:decoder.final_layer_norm.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:562] Total Trainable Params: 60506624\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.809 algo-1:27 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-05-11 11:31:25.810 algo-1:27 INFO hook.py:485] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"run_glue_t5.py\", line 591, in <module>\u001b[0m\n",
      "\u001b[34mmain()\n",
      "  File \"run_glue_t5.py\", line 509, in main\u001b[0m\n",
      "\u001b[34mtrain_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 1400, in train\u001b[0m\n",
      "\u001b[34mtr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 1984, in training_step\u001b[0m\n",
      "\u001b[34mloss = self.compute_loss(model, inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 2016, in compute_loss\u001b[0m\n",
      "\u001b[34moutputs = model(**inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1149, in _call_impl\u001b[0m\n",
      "\u001b[34mresult = forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 1635, in forward\u001b[0m\n",
      "\u001b[34mdecoder_outputs = self.decoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1149, in _call_impl\u001b[0m\n",
      "\u001b[34mresult = forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\", line 933, in forward\u001b[0m\n",
      "\u001b[34mbatch_size, seq_length = input_shape\u001b[0m\n",
      "\u001b[34mValueError: not enough values to unpack (expected 2, got 1)\u001b[0m\n",
      "\u001b[34m0%|          | 0/3796 [00:03<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2022-05-11 11:31:28,458 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-05-11 11:31:28,458 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n",
      " 0%|          | 0/3796 [00:03<?, ?it/s]\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\"\u001b[0m\n",
      "\u001b[34m2022-05-11 11:31:28,458 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-05-11 11:31:55 Uploading - Uploading generated training model\n",
      "2022-05-11 11:31:55 Failed - Training job failed\n",
      "ProfilerReport-1652268269: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-pytorch-training-2022-05-11-11-24-29-437: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n 0%|          | 0/3796 [00:03<?, ?it/s]\"\nCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-b16382994147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# starting the train job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhuggingface_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3337\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m             )\n\u001b[1;32m   3341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-pytorch-training-2022-05-11-11-24-29-437: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ValueError: not enough values to unpack (expected 2, got 1)\n 0%|          | 0/3796 [00:03<?, ?it/s]\"\nCommand \"/opt/conda/bin/python3.8 run_glue_t5.py --do_train True --learning_rate 2e-05 --max_seq_length 128 --model_name_or_path t5-small --num_train_epochs 1 --output_dir /opt/ml/model/t5_small --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/val/val.csv\", exit code: 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit({'train': train_input_path, 'test': test_input_path, 'val':val_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d141c661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae3cc07ae3a491b92cdba590e48c0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b76f845b0240ceb1c25f3567258923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/cola (download: 368.14 KiB, generated: 596.73 KiB, post-processed: Unknown size, total: 964.86 KiB) to /home/ec2-user/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8ad52457d04f2d90add54e9d8d7c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/377k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f25254b6ba4900b1c2fe8e454b5267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7232f380c5e4b1bbadfb3b16530cb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2a6bc1197c44e7994f8e5fb85e2acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/ec2-user/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2b9e3cf14340f4b4e6a325d9f752ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cola_data = datasets.load_dataset(\"glue\", 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "02f32f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "168e10ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '菲布理',\n",
       " 'label': 2,\n",
       " 'input_ids': [3, 2, 1],\n",
       " 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317ddd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b07e3783fbec941e7f30356639d63a10837302918fd986685bef6fde1891b83c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('685_final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
