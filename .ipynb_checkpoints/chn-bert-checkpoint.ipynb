{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4101839-cd24-40b4-87d9-b9445593d7bc",
   "metadata": {},
   "source": [
    "# Data pre-processing & tokenization\n",
    "\n",
    "CS685 Spring 2022 <br />\n",
    "Apr. 2, 2022<br />\n",
    "Hongyu Tu <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9b3e20-b1e3-4e6d-b52d-21e0742c6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3724e61-ec00-417f-a8ad-7ba8d9cfb8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a14e1b-4ac0-41a8-bc3c-3fff29fa8955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba2e2c9-8d99-4a6a-9d29-5ec2027a56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lst = []\n",
    "\n",
    "for i in ['danmu', 'comment']:\n",
    "    with open('{}_token_main.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "    with open('{}_dist_main.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "        \n",
    "danmu_token, danmu_dist, comment_token, comment_dist = tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "821debb3-c03a-41b6-bccf-b8764399e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred, answer):\n",
    "    correct = torch.argmax(answer).item()\n",
    "    pred = torch.argmax(pred).item()\n",
    "    return 1 if pred == correct else 0\n",
    "    \n",
    "    # if 1 in answer: \n",
    "    #     correct = torch.argmax(answer).item()\n",
    "    #     pred = torch.argmax(pred).item()\n",
    "    #     return 1 if pred == correct else 0\n",
    "    # else:\n",
    "    #     val, length = 0, 10\n",
    "    #     correct_idx = torch.where(answer != 0)[0].detach().cpu().numpy()\n",
    "    #     if len(correct_idx) > 10:\n",
    "    #         length = len(correct_idx)\n",
    "    #     pred_idx = torch.where(pred != 0)[0].detach().cpu().numpy()\n",
    "    #     for i in correct_idx:\n",
    "    #         if i in pred_idx[:length]:\n",
    "    #             val += 1\n",
    "        # torch.sum(pred[correct_idx]).item()\n",
    "        # return val/length\n",
    "\n",
    "def tok_ten(token_lst, dist_lst):\n",
    "    lst = [tokenizer(i)['input_ids'][1:-1] for i in token_lst]\n",
    "    max_length = np.max(np.array([len(i) for i in lst]))\n",
    "    tmp_lst = []\n",
    "    for i in range(len(lst)):\n",
    "        tmp = np.concatenate([lst[i], -np.ones(1 + max_length - len(lst[i]))]) \n",
    "        tmp_lst.append(tmp[:5])\n",
    "    \n",
    "    tmp = np.zeros_like(dist_lst)\n",
    "    for i, row in enumerate(dist_lst):\n",
    "        idx = np.argmax(row)\n",
    "        # tmp[i][row != 0] = 1\n",
    "        tmp[i][idx] = 1\n",
    "    dist_lst = tmp\n",
    "        \n",
    "    output = torch.from_numpy(np.array(tmp_lst).astype(np.float32)).to(device=device), \\\n",
    "             torch.from_numpy(np.array(dist_lst).astype(np.float32)).to(device=device)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c569a8f8-9358-4183-a7bb-04697d9b662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "danmu_x, danmu_y = tok_ten(danmu_token, danmu_dist)\n",
    "comment_x, comment_y = tok_ten(comment_token, comment_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093db41-b16a-4a01-9c7d-f53982f72e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6124ecdb-1f1f-4bf1-9c4a-a24f69efef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(danmu_x, danmu_y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "X_train.shape[0], X_val.shape[0], X_test.shape[0]\n",
    "inputDim, outputDim = X_train.shape[1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749e508-f9bf-4b77-b2c4-0018985a2149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1853b640-66f6-4393-a308-cc0d8e4ffa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1, size2 = inputDim, outputDim\n",
    "L1, L2, L3 = 50, 50, 50\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(size1, L1),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(L1, L2),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(L2, L3),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(L3, size2),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b88d0b9f-776f-4f52-9521-83018eaa1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(X_train)\n",
    "# learningRate = 1e-8\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1460e3d-afc4-41ee-b7bd-777b9ab01dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                              | 12/2000 [00:00<00:17, 111.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 3.048682928085327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▎                                                             | 419/2000 [00:03<00:14, 111.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400, loss 3.0069832801818848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████▊                                                       | 586/2000 [00:05<00:12, 111.78it/s]"
     ]
    }
   ],
   "source": [
    "loss_his = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rand_idx = np.random.permutation(length)[:int(length/10)]\n",
    "    x = X_train[rand_idx]\n",
    "    y = y_train[rand_idx]\n",
    "    \n",
    "    model.train()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss_his.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    outputs = model(X_val)\n",
    "    loss = criterion(outputs, y_val)\n",
    "    \n",
    "    if epoch % int(epochs/5) == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc5e4e-f214-48ea-a892-3dc3e628d266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45563eb-071f-41ab-a65c-b2465a7e3a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03b858-6fa2-4a9c-8a31-dbd416e6c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = X_test, y_test\n",
    "outputs = model(x)\n",
    "m = nn.Softmax(dim=1)\n",
    "outputs = m(outputs)\n",
    "a = np.sum([score(outputs[i], y[i]) for i in range(len(x))])/len(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485def50-ebdd-4e70-a2e6-da2170d6a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e53eb-b54b-4850-af6c-e7f8f57d020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(loss_his))), loss_his)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
