{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4101839-cd24-40b4-87d9-b9445593d7bc",
   "metadata": {},
   "source": [
    "# Data pre-processing & tokenization\n",
    "\n",
    "CS685 Spring 2022 <br />\n",
    "Apr. 2, 2022<br />\n",
    "Hongyu Tu <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9b3e20-b1e3-4e6d-b52d-21e0742c6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3724e61-ec00-417f-a8ad-7ba8d9cfb8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a14e1b-4ac0-41a8-bc3c-3fff29fa8955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba2e2c9-8d99-4a6a-9d29-5ec2027a56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lst = []\n",
    "\n",
    "for i in ['danmu', 'comment']:\n",
    "    with open('{}_token.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "    with open('{}_dist.pkl'.format(i), 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        tmp_lst.append(tmp)\n",
    "        \n",
    "danmu_token, danmu_dist, comment_token, comment_dist = tmp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821debb3-c03a-41b6-bccf-b8764399e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_ten(token_lst, dist_lst):\n",
    "    lst = [tokenizer(i)['input_ids'][1:-1] for i in token_lst]\n",
    "    max_length = np.max(np.array([len(i) for i in lst]))\n",
    "    tmp_lst = []\n",
    "    for i in range(len(lst)):\n",
    "        tmp = np.concatenate([lst[i], -np.ones(1 + max_length - len(lst[i]))]) \n",
    "        tmp_lst.append(tmp)\n",
    "    output = torch.from_numpy(np.array(tmp_lst).astype(np.float32)).to(device=device), \\\n",
    "             torch.from_numpy(np.array(dist_lst).astype(np.float32)).to(device=device)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c569a8f8-9358-4183-a7bb-04697d9b662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "danmu_x, danmu_y = tok_ten(danmu_token, danmu_dist)\n",
    "comment_x, comment_y = tok_ten(comment_token, comment_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346417e2-0db5-467f-b0f2-2586d6620806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6124ecdb-1f1f-4bf1-9c4a-a24f69efef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(danmu_x, danmu_y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6e21a23-44a8-41e1-abbe-b6333c907e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0], X_val.shape[0], X_test.shape[0]\n",
    "inputDim, outputDim = X_train.shape[1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33da313d-aa1e-4801-ba03-152118e416ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6b4f350-fb64-4c28-a167-28e79ba9074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(x):\n",
    "    return torch.argmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9308e8f-84c7-410c-a434-c578cb67ace4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1853b640-66f6-4393-a308-cc0d8e4ffa36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_17572/3510429219.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\tomtu\\AppData\\Local\\Temp/ipykernel_17572/3510429219.py\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    argmax()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "size1, size2 = inputDim, outputDim\n",
    "L1, L2, L3 = 150, 250, 250\n",
    "\n",
    "model = nn.Sequential(\n",
    "    \n",
    "    nn.Linear(size1, L1),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(L1, L2),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(L2, L3),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(L3, size2),\n",
    "    nn.LogSoftmax(dim=1)\n",
    "    argmax()\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b88d0b9f-776f-4f52-9521-83018eaa1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(X_train)\n",
    "learningRate = 1e-8\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1460e3d-afc4-41ee-b7bd-777b9ab01dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 9/10000 [00:00<01:51, 89.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 82.76221466064453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                    | 1017/10000 [00:09<01:20, 111.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, loss 3.9954311847686768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                            | 2025/10000 [00:18<01:10, 112.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2000, loss 3.9777848720550537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▉                                                     | 3019/10000 [00:27<01:03, 109.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3000, loss 3.975257396697998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▌                                             | 4014/10000 [00:35<00:53, 112.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4000, loss 3.985334873199463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▏                                     | 5022/10000 [00:44<00:45, 109.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5000, loss 4.00213623046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▋                              | 6018/10000 [00:53<00:35, 111.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6000, loss 4.0153093338012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▎                      | 7012/10000 [01:02<00:26, 111.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7000, loss 4.045955181121826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▉               | 8020/10000 [01:11<00:17, 111.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8000, loss 4.067865371704102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▌       | 9016/10000 [01:20<00:08, 112.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9000, loss 4.109577178955078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:29<00:00, 112.10it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_his = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rand_idx = np.random.permutation(length)[:int(length/10)]\n",
    "    x = X_train[rand_idx]\n",
    "    y = y_train[rand_idx]\n",
    "    \n",
    "    model.train()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss_his.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    outputs = model(X_val)\n",
    "    loss = criterion(outputs, y_val)\n",
    "    \n",
    "    if epoch % int(epochs/10) == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc5e4e-f214-48ea-a892-3dc3e628d266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86c0d0-1f90-4326-8ad1-8a110af08f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef0f09-3d46-4d30-b69f-fe679700c2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d769ed-5cf2-470d-b89a-b36a2d01a58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4aced671-275a-48ed-9927-bd973b7272eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bab7b-efda-4abc-88b6-ef8fdb123961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a94246-0820-4e05-8273-f123818ca274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e7e011e-be01-4d27-8d46-445f9042f622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([123, 105, 118, 102,  34, 104,  52,   8, 113,  70, 108,  82,  43, 100,\n",
       "         27,   7,  64,  18,  99, 101,  76,   9,  12, 122,  58, 120, 103, 119,\n",
       "         89,  95, 124, 125,  94, 116,   0, 121,  33,  91,  42,  17,  31,  21,\n",
       "         85,  10,  49,  87,  22,  32,  16,  15,  11, 115, 114,   2,  28, 112,\n",
       "         55,  74,  68,  62,  29,  67,  30,  86,  92,  57,  51,  40,   1,  19,\n",
       "         84,  97,  50,  23,  90,  56,  41,  61,   4,  88,  60,  66,  48,  54,\n",
       "        110, 117,  63, 106,  83,  59,  20,  98,   5,  93,   3,  39,  96,  24,\n",
       "          6,  73,  25,  69,  38,  79,  47,  75,  45, 111,  13,  80,  14,  72,\n",
       "         26,  81,  77,  36,  53,  37,  46,  44,  65,  71, 109, 107,  78,  35],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(outputs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7df9eef-030f-4a3e-9178-088d2027b720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([124, 125, 122, 123, 121, 120, 118, 119, 115, 114, 112, 113, 117, 116,\n",
       "        110, 111, 103, 102, 100, 101,  97,  96,  98,  99, 107, 106, 104, 105,\n",
       "        109, 108,  94,  95,  79,  78,  76,  77,  73,  72,  74,  75,  67,  66,\n",
       "         64,  65,  69,  68,  70,  71,  87,  86,  84,  85,  81,  80,  82,  83,\n",
       "         91,  90,  88,  89,  93,  92,  62,  63,  31,  30,  28,  29,  25,  24,\n",
       "         26,  27,  19,  18,  16,  17,  21,  20,  22,  23,   7,   6,   4,   5,\n",
       "          1,   0,   2,   3,  11,  10,   8,   9,  13,  12,  14,  15,  55,  47,\n",
       "         44,  46,  41,  40,  42,  43,  35,  34,  32,  33,  37,  36,  38,  39,\n",
       "         59,  54,  52,  53,  49,  48,  50,  51,  61,  58,  56,  57,  60,  45],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(y_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350597aa-0ac8-419a-91a8-f98ea2038e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad145a8c-e29b-40b6-a310-2b257bf44ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "318e53eb-b54b-4850-af6c-e7f8f57d020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(loss_his))), loss_his)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
